{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1rsFuLddRiZAGMBrv8r87mgvQasHSurRk","authorship_tag":"ABX9TyOmLSEfra4TfIhceo0Cj6mx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **JSON file analysis experiment**"],"metadata":{"id":"w7qF1Yn95EYa"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-o_r8Czi0_3","executionInfo":{"status":"ok","timestamp":1744303704942,"user_tz":240,"elapsed":21538,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"64b13d65-e0e5-4a65-f328-7451979cfadf"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Reduced JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/reduced_LLaVA-mix665k.json\n","ðŸ§® Original keys: 52806 â†’ Filtered keys: 283\n","âœ… Reduced JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/reduced_LLaVA-Pretrain.json\n","ðŸ§® Original keys: 140583 â†’ Filtered keys: 159\n"]}],"source":["import json\n","import pandas as pd\n","from pathlib import Path\n","\n","def create_reduced_json(input_json_path, output_json_path, valid_keys_set):\n","    with open(input_json_path, \"r\") as f:\n","        full_data = json.load(f)\n","\n","    reduced_data = {}\n","    for key in full_data:\n","        if key.lower() in valid_keys_set:\n","            reduced_data[key] = full_data[key]\n","\n","    with open(output_json_path, \"w\") as f:\n","        json.dump(reduced_data, f)\n","\n","    print(f\"âœ… Reduced JSON saved to: {output_json_path}\")\n","    print(f\"ðŸ§® Original keys: {len(full_data)} â†’ Filtered keys: {len(reduced_data)}\")\n","\n","# Loading object list and normalize\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","df = pd.read_csv(csv_path)\n","valid_objects = set(df[\"Object\"].dropna().astype(str).str.lower())\n","\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","input_jsons = {\n","    \"LLaVA-mix665k\": base_path / \"object_cooccurences_LLaVA-mix665k.json\",\n","    \"LLaVA-Pretrain\": base_path / \"object_cooccurences_LLaVA-Pretrain.json\"\n","}\n","output_jsons = {\n","    name: base_path / f\"reduced_{name}.json\" for name in input_jsons\n","}\n","\n","# Processing both JSON files\n","for name in input_jsons:\n","    create_reduced_json(input_jsons[name], output_jsons[name], valid_objects)\n","\n"]},{"cell_type":"code","source":["from pathlib import Path\n","\n","def filter_and_format_json(input_json_path, output_json_path, valid_objects_set):\n","    with open(input_json_path, \"r\") as f:\n","        raw_data = json.load(f)\n","\n","    filtered_data = {}\n","    for key, val_dict in raw_data.items():\n","        key_lower = key.lower()\n","        if key_lower not in valid_objects_set:\n","            continue\n","        filtered_val = {k: v for k, v in val_dict.items() if k.lower() in valid_objects_set}\n","        if filtered_val:\n","            filtered_data[key] = filtered_val\n","\n","    with open(output_json_path, \"w\") as f:\n","        for key, val in filtered_data.items():\n","            json_str = json.dumps({key: val}, indent=2)\n","            f.write(json_str + \"\\n\\n\")\n","\n","    print(f\"âœ… Final filtered and formatted JSON saved to: {output_json_path}\")\n","    print(f\"ðŸ“¦ Total keys written: {len(filtered_data)}\")\n","\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","df = pd.read_csv(csv_path)\n","valid_objects = set(df[\"Object\"].dropna().astype(str).str.lower())\n","\n","# File paths\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","input_jsons = {\n","    \"reduced_LLaVA-mix665k.json\": base_path / \"reduced_LLaVA-mix665k.json\",\n","    \"reduced_LLaVA-Pretrain.json\": base_path / \"reduced_LLaVA-Pretrain.json\"\n","}\n","output_jsons = {\n","    name: base_path / f\"final_filtered_{name}\" for name in input_jsons\n","}\n","\n","# executing for both files\n","for name in input_jsons:\n","    filter_and_format_json(input_jsons[name], output_jsons[name], valid_objects)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVoOwzwXnR-i","executionInfo":{"status":"ok","timestamp":1744303920914,"user_tz":240,"elapsed":433,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"501214df-fde5-4df5-e416-75b61272d46d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Final filtered and formatted JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/final_filtered_reduced_LLaVA-mix665k.json\n","ðŸ“¦ Total keys written: 270\n","âœ… Final filtered and formatted JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/final_filtered_reduced_LLaVA-Pretrain.json\n","ðŸ“¦ Total keys written: 146\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","def count_kv_pairs(json_path):\n","    with open(json_path, \"r\") as f:\n","        content = f.read()\n","\n","    blocks = [block for block in content.strip().split(\"\\n\\n\") if block.strip()]\n","\n","    key_counter = Counter()\n","    for block in blocks:\n","        try:\n","            d = json.loads(block)\n","            for key in d:\n","                key_counter[key] += 1\n","        except json.JSONDecodeError:\n","            print(\"âš ï¸ Skipped an invalid block\")\n","\n","    total_kv = len(key_counter)\n","    duplicates = {k: v for k, v in key_counter.items() if v > 1}\n","\n","    return total_kv, duplicates\n","\n","# Paths to files\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","paths = {\n","    \"Pretrain\": base_path / \"final_filtered_reduced_LLaVA-Pretrain.json\",\n","    \"Mix665k\": base_path / \"final_filtered_reduced_LLaVA-mix665k.json\"\n","}\n","\n","# Run stats\n","for label, path in paths.items():\n","    total_keys, duplicate_keys = count_kv_pairs(path)\n","    print(f\"ðŸ“Š {label} JSON Stats\")\n","    print(f\"Total unique keys: {total_keys}\")\n","    print(f\"Duplicate keys found: {len(duplicate_keys)}\")\n","    if duplicate_keys:\n","        print(f\"Sample duplicates: {list(duplicate_keys.items())[:5]}\")\n","    print()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gK2ZGz_ogfR","executionInfo":{"status":"ok","timestamp":1744304215177,"user_tz":240,"elapsed":43,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"91852b60-5088-4c4e-9ee7-dad5d00b1c8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ“Š Pretrain JSON Stats\n","Total unique keys: 146\n","Duplicate keys found: 0\n","\n","ðŸ“Š Mix665k JSON Stats\n","Total unique keys: 270\n","Duplicate keys found: 0\n","\n"]}]},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","from collections import Counter\n","\n","def list_sorted_keys(json_path):\n","    with open(json_path, \"r\") as f:\n","        content = f.read()\n","\n","    blocks = [block for block in content.strip().split(\"\\n\\n\") if block.strip()]\n","\n","    key_counter = Counter()\n","    keys = []\n","\n","    for block in blocks:\n","        try:\n","            d = json.loads(block)\n","            for key in d:\n","                key_counter[key] += 1\n","                keys.append(key)\n","        except json.JSONDecodeError:\n","            print(\"âš ï¸ Skipped an invalid block\")\n","\n","    duplicates = {k: v for k, v in key_counter.items() if v > 1}\n","    sorted_keys = sorted(set(keys), key=lambda x: x.lower())\n","\n","    print(f\"ðŸ“Š {json_path.name} Stats\")\n","    print(f\"Total unique keys: {len(set(keys))}\")\n","    print(f\"Duplicate keys found: {len(duplicates)}\\n\")\n","\n","    print(\"ðŸ”¤ Sorted Unique Keys:\")\n","    for k in sorted_keys:\n","        print(k)\n","\n","# Paths to check\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","pretrain_path = base_path / \"final_filtered_reduced_LLaVA-Pretrain.json\"\n","mix_path = base_path / \"final_filtered_reduced_LLaVA-mix665k.json\"\n","\n","# Run for both files\n","list_sorted_keys(pretrain_path)\n","print(\"\\n\" + \"=\"*60 + \"\\n\")\n","list_sorted_keys(mix_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGY5FkBwpJ1n","executionInfo":{"status":"ok","timestamp":1744304384999,"user_tz":240,"elapsed":25,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"81120e1e-ee29-4972-85f7-63837258c306"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ“Š final_filtered_reduced_LLaVA-Pretrain.json Stats\n","Total unique keys: 146\n","Duplicate keys found: 0\n","\n","ðŸ”¤ Sorted Unique Keys:\n","agent\n","antiquity\n","article\n","bed\n","beef\n","bitch\n","block\n","blood\n","body\n","button\n","buttons\n","carpet\n","catch\n","cause\n","cement\n","center\n","chalk\n","challenge\n","charm\n","chemistry\n","cloth\n","commodity\n","complaint\n","cone\n","cones\n","consolidation\n","construction\n","cosmos\n","cover\n","covering\n","crank\n","creation\n","curio\n","curiosity\n","decker\n","decoration\n","dissent\n","draw\n","earth\n","element\n","enamel\n","essence\n","excavation\n","fabric\n","facility\n","filler\n","film\n","fixture\n","float\n","floater\n","fluid\n","food\n","formation\n","fuel\n","glass\n","glasses\n","good\n","goods\n","ground\n","grounds\n","growth\n","head\n","humor\n","ice\n","ink\n","inks\n","insert\n","installation\n","jelly\n","juice\n","keepsake\n","kick\n","land\n","layer\n","lemon\n","line\n","location\n","lot\n","lots\n","love\n","marijuana\n","marker\n","material\n","matter\n","mechanism\n","media\n","medium\n","melancholy\n","milk\n","mixture\n","moon\n","neighbor\n","nest\n","object\n","opening\n","ornament\n","padding\n","part\n","passion\n","pavement\n","paving\n","portion\n","process\n","prop\n","property\n","props\n","protest\n","radiator\n","remains\n","restoration\n","ribbon\n","rock\n","sample\n","seed\n","serum\n","sheet\n","shiner\n","slip\n","snake\n","soil\n","sphere\n","square\n","stone\n","strip\n","structure\n","stuff\n","substance\n","surface\n","textile\n","thing\n","thread\n","token\n","toy\n","track\n","trash\n","trifle\n","trivia\n","unit\n","universe\n","vehicle\n","wall\n","way\n","ways\n","web\n","weight\n","world\n","\n","============================================================\n","\n","ðŸ“Š final_filtered_reduced_LLaVA-mix665k.json Stats\n","Total unique keys: 270\n","Duplicate keys found: 0\n","\n","ðŸ”¤ Sorted Unique Keys:\n","agent\n","Allergen\n","allergen\n","antiquity\n","article\n","Bed\n","bed\n","beef\n","Beef\n","Block\n","block\n","Blood\n","blood\n","Body\n","body\n","button\n","Button\n","buttons\n","Buttons\n","carpet\n","Carpet\n","Catch\n","catch\n","Cause\n","cause\n","Cement\n","cement\n","center\n","Center\n","chalk\n","Challenge\n","challenge\n","charm\n","Charm\n","chemistry\n","cloth\n","Cloth\n","commodity\n","complaint\n","cone\n","Cone\n","Cones\n","cones\n","consolidation\n","construction\n","Construction\n","cosmos\n","Cover\n","cover\n","covering\n","Covering\n","crank\n","creation\n","Creation\n","curio\n","Curio\n","curiosity\n","Curiosity\n","decker\n","Decoration\n","decoration\n","dissent\n","draw\n","earth\n","Earth\n","Element\n","element\n","Enamel\n","enamel\n","essence\n","excavation\n","Excavation\n","exception\n","existence\n","Fabric\n","fabric\n","Facility\n","facility\n","Filler\n","filler\n","Film\n","film\n","finding\n","fixture\n","Fixture\n","float\n","Float\n","Floater\n","floater\n","fluid\n","Fluid\n","food\n","Food\n","Formation\n","formation\n","Fuel\n","fuel\n","glass\n","Glass\n","Glasses\n","glasses\n","good\n","goods\n","Goods\n","ground\n","Ground\n","Grounds\n","grounds\n","Growth\n","growth\n","hail\n","Head\n","head\n","humor\n","Humor\n","ice\n","ICE\n","Ice\n","ink\n","inks\n","insert\n","Installation\n","installation\n","instrumentation\n","Instrumentation\n","jelly\n","Jelly\n","juice\n","Juice\n","Keepsake\n","keepsake\n","Kick\n","kick\n","land\n","Land\n","layer\n","Layer\n","Lemon\n","lemon\n","Line\n","line\n","location\n","Location\n","lot\n","lots\n","Lots\n","LOVE\n","Love\n","love\n","lubricant\n","Marijuana\n","marijuana\n","marker\n","Marker\n","material\n","Material\n","matter\n","mechanism\n","Mechanism\n","Media\n","media\n","medium\n","melancholy\n","milk\n","Milk\n","mixture\n","moon\n","neighbor\n","Nest\n","nest\n","nutrient\n","Nutrient\n","object\n","Object\n","Opening\n","opening\n","ornament\n","padding\n","Padding\n","Part\n","part\n","Passion\n","passion\n","pavement\n","Pavement\n","paving\n","Portion\n","portion\n","process\n","Process\n","Prop\n","prop\n","Property\n","property\n","Props\n","props\n","protest\n","Protest\n","radiator\n","Rarity\n","rarity\n","relic\n","remains\n","Restoration\n","restoration\n","ribbon\n","Ribbon\n","rock\n","Rock\n","sample\n","Sample\n","seed\n","Seed\n","serum\n","Sheet\n","sheet\n","shiner\n","slip\n","Slip\n","Snake\n","snake\n","soil\n","Soil\n","sphere\n","square\n","stone\n","Stone\n","Strip\n","strip\n","Structure\n","structure\n","Stuff\n","stuff\n","substance\n","Surface\n","surface\n","tangle\n","textile\n","thing\n","Thing\n","thread\n","Thread\n","token\n","toy\n","Toy\n","Track\n","track\n","Trash\n","trash\n","trifle\n","trivia\n","Unit\n","unit\n","universe\n","vehicle\n","Vehicle\n","wall\n","Wall\n","WAY\n","Way\n","way\n","Ways\n","ways\n","web\n","Web\n","Weight\n","weight\n","whole\n","world\n","World\n"]}]},{"cell_type":"code","source":["from collections import defaultdict\n","import json\n","from pathlib import Path\n","\n","def load_and_normalize(filepath):\n","    with open(filepath, \"r\") as f:\n","        content = f.read()\n","\n","    blocks = [block for block in content.strip().split(\"\\n\\n\") if block.strip()]\n","    merged = defaultdict(lambda: defaultdict(int))\n","\n","    for block in blocks:\n","        try:\n","            d = json.loads(block)\n","            for key, val_dict in d.items():\n","                key_lower = key.lower()\n","                for subkey, freq in val_dict.items():\n","                    subkey_lower = subkey.lower()\n","                    merged[key_lower][subkey_lower] += freq\n","        except json.JSONDecodeError:\n","            print(\"âš ï¸ Skipping invalid JSON block.\")\n","\n","    return merged\n","\n","def merge_two_dictionaries(dict1, dict2):\n","    for key, subdict in dict2.items():\n","        for subkey, freq in subdict.items():\n","            dict1[key][subkey] += freq\n","    return dict1\n","\n","def sort_nested_dict(d):\n","    sorted_dict = {}\n","    for key in sorted(d.keys()):\n","        sorted_sub = dict(sorted(d[key].items(), key=lambda x: -x[1]))\n","        sorted_dict[key] = sorted_sub\n","    return sorted_dict\n","\n","# File paths\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","pretrain_path = base_path / \"final_filtered_reduced_LLaVA-Pretrain.json\"\n","mix_path = base_path / \"final_filtered_reduced_LLaVA-mix665k.json\"\n","output_path = base_path / \"final_merged_sorted_cooccur.json\"\n","\n","# Load, normalize, and merge\n","pretrain_data = load_and_normalize(pretrain_path)\n","mix_data = load_and_normalize(mix_path)\n","merged = merge_two_dictionaries(pretrain_data, mix_data)\n","sorted_merged = sort_nested_dict(merged)\n","\n","# Save final result\n","with open(output_path, \"w\") as f:\n","    json.dump(sorted_merged, f, indent=2)\n","\n","print(f\"âœ… Final merged and sorted co-occurrence data saved to:\\n{output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BODQNmuipQZJ","executionInfo":{"status":"ok","timestamp":1744304758882,"user_tz":240,"elapsed":71,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"7f0afeb7-121f-474f-db7d-e6ccecbdd74b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Final merged and sorted co-occurrence data saved to:\n","/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\n"]}]},{"cell_type":"code","source":["# Path to the final cleaned and sorted file\n","final_json_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\")\n","\n","def verify_final_json_stats(filepath, expected_max_values=150):\n","    with open(filepath, \"r\") as f:\n","        data = json.load(f)\n","\n","    total_keys = len(data)\n","    too_many_values = {k: len(v) for k, v in data.items() if len(v) > expected_max_values}\n","\n","    print(f\"ðŸ“Š Total unique main objects (keys): {total_keys}\")\n","    if too_many_values:\n","        print(f\"âš ï¸ Keys with more than {expected_max_values} co-occurring objects:\")\n","        for k, count in too_many_values.items():\n","            print(f\"  - {k}: {count}\")\n","    else:\n","        print(f\"âœ… All keys have â‰¤ {expected_max_values} co-occurring objects\")\n","\n","    print(\"\\nðŸ” Sample order check (first 5 keys):\")\n","    for k in list(data.keys())[:5]:\n","        print(f\"  - {k}\")\n","        print(f\"    â†³ Top 3 co-objects: {list(data[k].items())[:3]}\")\n","    print(\"\\nðŸ“Œ Order of values is descending by frequency? Checking sample...\")\n","\n","    for k in list(data.keys())[:5]:\n","        freqs = list(data[k].values())\n","        if freqs != sorted(freqs, reverse=True):\n","            print(f\"âš ï¸ Order issue found in: {k}\")\n","        else:\n","            print(f\"âœ… {k} values are correctly ordered\")\n","\n","# Run verification\n","verify_final_json_stats(final_json_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkSekuJ5rUIh","executionInfo":{"status":"ok","timestamp":1744304951139,"user_tz":240,"elapsed":45,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"c3348cf2-185c-4860-d3e8-9477413a1c65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ“Š Total unique main objects (keys): 158\n","âœ… All keys have â‰¤ 150 co-occurring objects\n","\n","ðŸ” Sample order check (first 5 keys):\n","  - agent\n","    â†³ Top 3 co-objects: [('process', 19), ('milk', 14), ('food', 9)]\n","  - allergen\n","    â†³ Top 3 co-objects: [('food', 14), ('growth', 2), ('allergen', 2)]\n","  - antiquity\n","    â†³ Top 3 co-objects: [('stone', 4), ('structure', 4), ('charm', 3)]\n","  - article\n","    â†³ Top 3 co-objects: [('cover', 23), ('media', 15), ('part', 9)]\n","  - bed\n","    â†³ Top 3 co-objects: [('wall', 365), ('surface', 275), ('part', 198)]\n","\n","ðŸ“Œ Order of values is descending by frequency? Checking sample...\n","âœ… agent values are correctly ordered\n","âœ… allergen values are correctly ordered\n","âœ… antiquity values are correctly ordered\n","âœ… article values are correctly ordered\n","âœ… bed values are correctly ordered\n"]}]},{"cell_type":"code","source":["# Check which of the 160 objects are missing from the final JSON\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","final_json_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\"\n","\n","df = pd.read_csv(csv_path)\n","csv_objects = set(df[\"Object\"].dropna().astype(str).str.lower())\n","\n","with open(final_json_path, \"r\") as f:\n","    json_data = json.load(f)\n","json_keys = set(json_data.keys())\n","\n","missing = sorted(csv_objects - json_keys)\n","\n","print(f\"âŒ Missing objects ({len(missing)}):\")\n","for obj in missing:\n","    print(f\"- {obj}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B16nX_fRreoB","executionInfo":{"status":"ok","timestamp":1744305031065,"user_tz":240,"elapsed":25,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"d3e4dd88-3ffc-4b16-f35b-8d2d12ddaa85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âŒ Missing objects (1):\n","- extra\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from collections import Counter\n","\n","# Path to the CSV file\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","\n","df = pd.read_csv(csv_path)\n","objects_raw = df[\"Object\"].dropna().astype(str).tolist()\n","objects_normalized = [obj.strip().lower() for obj in objects_raw]\n","\n","# Counting frequency\n","object_counter = Counter(objects_normalized)\n","\n","unique_count = len(set(objects_normalized))\n","total_count = len(objects_normalized)\n","duplicates = {obj: count for obj, count in object_counter.items() if count > 1}\n","\n","# Output\n","print(f\"ðŸ”¢ Total objects (original): {total_count}\")\n","print(f\"ðŸ”¡ Unique objects (normalized): {unique_count}\")\n","print(f\"â™»ï¸ Duplicate entries found: {len(duplicates)}\")\n","\n","if duplicates:\n","    print(\"\\nðŸ” Duplicate examples:\")\n","    for obj, count in list(duplicates.items())[:10]:\n","        print(f\"- {obj}: {count} times\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSvg17dOsBI7","executionInfo":{"status":"ok","timestamp":1744305146191,"user_tz":240,"elapsed":14,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"92af21fb-836b-44d6-91df-132cc6b407ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ”¢ Total objects (original): 159\n","ðŸ”¡ Unique objects (normalized): 159\n","â™»ï¸ Duplicate entries found: 0\n"]}]},{"cell_type":"code","source":["# Path to the final merged JSON\n","final_json_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\"\n","\n","with open(final_json_path, \"r\") as f:\n","    data = json.load(f)\n","\n","multi_word_keys = [k for k in data if len(k.split()) > 1]\n","multi_word_values = set()\n","\n","for co_dict in data.values():\n","    for co_obj in co_dict:\n","        if len(co_obj.split()) > 1:\n","            multi_word_values.add(co_obj)\n","\n","print(f\"Total multi-word keys: {len(multi_word_keys)}\")\n","if multi_word_keys:\n","    print(\"Sample multi-word keys:\")\n","    for k in list(multi_word_keys)[:10]:\n","        print(f\"- {k}\")\n","\n","print(f\"\\nTotal multi-word co-occurring objects (values): {len(multi_word_values)}\")\n","if multi_word_values:\n","    print(\"Sample multi-word values:\")\n","    for v in list(multi_word_values)[:10]:\n","        print(f\"- {v}\")\n"],"metadata":{"id":"6eacvCysvJRG","executionInfo":{"status":"ok","timestamp":1744305955440,"user_tz":240,"elapsed":13,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"7c2d6cb9-557a-46e2-9cd9-f02dc2c137c3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total multi-word keys: 0\n","\n","Total multi-word co-occurring objects (values): 0\n"]}]}]}