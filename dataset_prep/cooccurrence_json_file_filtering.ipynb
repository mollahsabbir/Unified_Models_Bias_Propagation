{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1rsFuLddRiZAGMBrv8r87mgvQasHSurRk","authorship_tag":"ABX9TyOmLSEfra4TfIhceo0Cj6mx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **JSON file analysis experiment**"],"metadata":{"id":"w7qF1Yn95EYa"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-o_r8Czi0_3","executionInfo":{"status":"ok","timestamp":1744303704942,"user_tz":240,"elapsed":21538,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"64b13d65-e0e5-4a65-f328-7451979cfadf"},"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Reduced JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/reduced_LLaVA-mix665k.json\n","🧮 Original keys: 52806 → Filtered keys: 283\n","✅ Reduced JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/reduced_LLaVA-Pretrain.json\n","🧮 Original keys: 140583 → Filtered keys: 159\n"]}],"source":["import json\n","import pandas as pd\n","from pathlib import Path\n","\n","def create_reduced_json(input_json_path, output_json_path, valid_keys_set):\n","    with open(input_json_path, \"r\") as f:\n","        full_data = json.load(f)\n","\n","    reduced_data = {}\n","    for key in full_data:\n","        if key.lower() in valid_keys_set:\n","            reduced_data[key] = full_data[key]\n","\n","    with open(output_json_path, \"w\") as f:\n","        json.dump(reduced_data, f)\n","\n","    print(f\"✅ Reduced JSON saved to: {output_json_path}\")\n","    print(f\"🧮 Original keys: {len(full_data)} → Filtered keys: {len(reduced_data)}\")\n","\n","# Loading object list and normalize\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","df = pd.read_csv(csv_path)\n","valid_objects = set(df[\"Object\"].dropna().astype(str).str.lower())\n","\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","input_jsons = {\n","    \"LLaVA-mix665k\": base_path / \"object_cooccurences_LLaVA-mix665k.json\",\n","    \"LLaVA-Pretrain\": base_path / \"object_cooccurences_LLaVA-Pretrain.json\"\n","}\n","output_jsons = {\n","    name: base_path / f\"reduced_{name}.json\" for name in input_jsons\n","}\n","\n","# Processing both JSON files\n","for name in input_jsons:\n","    create_reduced_json(input_jsons[name], output_jsons[name], valid_objects)\n","\n"]},{"cell_type":"code","source":["from pathlib import Path\n","\n","def filter_and_format_json(input_json_path, output_json_path, valid_objects_set):\n","    with open(input_json_path, \"r\") as f:\n","        raw_data = json.load(f)\n","\n","    filtered_data = {}\n","    for key, val_dict in raw_data.items():\n","        key_lower = key.lower()\n","        if key_lower not in valid_objects_set:\n","            continue\n","        filtered_val = {k: v for k, v in val_dict.items() if k.lower() in valid_objects_set}\n","        if filtered_val:\n","            filtered_data[key] = filtered_val\n","\n","    with open(output_json_path, \"w\") as f:\n","        for key, val in filtered_data.items():\n","            json_str = json.dumps({key: val}, indent=2)\n","            f.write(json_str + \"\\n\\n\")\n","\n","    print(f\"✅ Final filtered and formatted JSON saved to: {output_json_path}\")\n","    print(f\"📦 Total keys written: {len(filtered_data)}\")\n","\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","df = pd.read_csv(csv_path)\n","valid_objects = set(df[\"Object\"].dropna().astype(str).str.lower())\n","\n","# File paths\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","input_jsons = {\n","    \"reduced_LLaVA-mix665k.json\": base_path / \"reduced_LLaVA-mix665k.json\",\n","    \"reduced_LLaVA-Pretrain.json\": base_path / \"reduced_LLaVA-Pretrain.json\"\n","}\n","output_jsons = {\n","    name: base_path / f\"final_filtered_{name}\" for name in input_jsons\n","}\n","\n","# executing for both files\n","for name in input_jsons:\n","    filter_and_format_json(input_jsons[name], output_jsons[name], valid_objects)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVoOwzwXnR-i","executionInfo":{"status":"ok","timestamp":1744303920914,"user_tz":240,"elapsed":433,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"501214df-fde5-4df5-e416-75b61272d46d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Final filtered and formatted JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/final_filtered_reduced_LLaVA-mix665k.json\n","📦 Total keys written: 270\n","✅ Final filtered and formatted JSON saved to: /content/drive/MyDrive/Grad/CAP6412-0001/Project/final_filtered_reduced_LLaVA-Pretrain.json\n","📦 Total keys written: 146\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","def count_kv_pairs(json_path):\n","    with open(json_path, \"r\") as f:\n","        content = f.read()\n","\n","    blocks = [block for block in content.strip().split(\"\\n\\n\") if block.strip()]\n","\n","    key_counter = Counter()\n","    for block in blocks:\n","        try:\n","            d = json.loads(block)\n","            for key in d:\n","                key_counter[key] += 1\n","        except json.JSONDecodeError:\n","            print(\"⚠️ Skipped an invalid block\")\n","\n","    total_kv = len(key_counter)\n","    duplicates = {k: v for k, v in key_counter.items() if v > 1}\n","\n","    return total_kv, duplicates\n","\n","# Paths to files\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","paths = {\n","    \"Pretrain\": base_path / \"final_filtered_reduced_LLaVA-Pretrain.json\",\n","    \"Mix665k\": base_path / \"final_filtered_reduced_LLaVA-mix665k.json\"\n","}\n","\n","# Run stats\n","for label, path in paths.items():\n","    total_keys, duplicate_keys = count_kv_pairs(path)\n","    print(f\"📊 {label} JSON Stats\")\n","    print(f\"Total unique keys: {total_keys}\")\n","    print(f\"Duplicate keys found: {len(duplicate_keys)}\")\n","    if duplicate_keys:\n","        print(f\"Sample duplicates: {list(duplicate_keys.items())[:5]}\")\n","    print()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3gK2ZGz_ogfR","executionInfo":{"status":"ok","timestamp":1744304215177,"user_tz":240,"elapsed":43,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"91852b60-5088-4c4e-9ee7-dad5d00b1c8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 Pretrain JSON Stats\n","Total unique keys: 146\n","Duplicate keys found: 0\n","\n","📊 Mix665k JSON Stats\n","Total unique keys: 270\n","Duplicate keys found: 0\n","\n"]}]},{"cell_type":"code","source":["import json\n","from pathlib import Path\n","from collections import Counter\n","\n","def list_sorted_keys(json_path):\n","    with open(json_path, \"r\") as f:\n","        content = f.read()\n","\n","    blocks = [block for block in content.strip().split(\"\\n\\n\") if block.strip()]\n","\n","    key_counter = Counter()\n","    keys = []\n","\n","    for block in blocks:\n","        try:\n","            d = json.loads(block)\n","            for key in d:\n","                key_counter[key] += 1\n","                keys.append(key)\n","        except json.JSONDecodeError:\n","            print(\"⚠️ Skipped an invalid block\")\n","\n","    duplicates = {k: v for k, v in key_counter.items() if v > 1}\n","    sorted_keys = sorted(set(keys), key=lambda x: x.lower())\n","\n","    print(f\"📊 {json_path.name} Stats\")\n","    print(f\"Total unique keys: {len(set(keys))}\")\n","    print(f\"Duplicate keys found: {len(duplicates)}\\n\")\n","\n","    print(\"🔤 Sorted Unique Keys:\")\n","    for k in sorted_keys:\n","        print(k)\n","\n","# Paths to check\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","pretrain_path = base_path / \"final_filtered_reduced_LLaVA-Pretrain.json\"\n","mix_path = base_path / \"final_filtered_reduced_LLaVA-mix665k.json\"\n","\n","# Run for both files\n","list_sorted_keys(pretrain_path)\n","print(\"\\n\" + \"=\"*60 + \"\\n\")\n","list_sorted_keys(mix_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hGY5FkBwpJ1n","executionInfo":{"status":"ok","timestamp":1744304384999,"user_tz":240,"elapsed":25,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"81120e1e-ee29-4972-85f7-63837258c306"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 final_filtered_reduced_LLaVA-Pretrain.json Stats\n","Total unique keys: 146\n","Duplicate keys found: 0\n","\n","🔤 Sorted Unique Keys:\n","agent\n","antiquity\n","article\n","bed\n","beef\n","bitch\n","block\n","blood\n","body\n","button\n","buttons\n","carpet\n","catch\n","cause\n","cement\n","center\n","chalk\n","challenge\n","charm\n","chemistry\n","cloth\n","commodity\n","complaint\n","cone\n","cones\n","consolidation\n","construction\n","cosmos\n","cover\n","covering\n","crank\n","creation\n","curio\n","curiosity\n","decker\n","decoration\n","dissent\n","draw\n","earth\n","element\n","enamel\n","essence\n","excavation\n","fabric\n","facility\n","filler\n","film\n","fixture\n","float\n","floater\n","fluid\n","food\n","formation\n","fuel\n","glass\n","glasses\n","good\n","goods\n","ground\n","grounds\n","growth\n","head\n","humor\n","ice\n","ink\n","inks\n","insert\n","installation\n","jelly\n","juice\n","keepsake\n","kick\n","land\n","layer\n","lemon\n","line\n","location\n","lot\n","lots\n","love\n","marijuana\n","marker\n","material\n","matter\n","mechanism\n","media\n","medium\n","melancholy\n","milk\n","mixture\n","moon\n","neighbor\n","nest\n","object\n","opening\n","ornament\n","padding\n","part\n","passion\n","pavement\n","paving\n","portion\n","process\n","prop\n","property\n","props\n","protest\n","radiator\n","remains\n","restoration\n","ribbon\n","rock\n","sample\n","seed\n","serum\n","sheet\n","shiner\n","slip\n","snake\n","soil\n","sphere\n","square\n","stone\n","strip\n","structure\n","stuff\n","substance\n","surface\n","textile\n","thing\n","thread\n","token\n","toy\n","track\n","trash\n","trifle\n","trivia\n","unit\n","universe\n","vehicle\n","wall\n","way\n","ways\n","web\n","weight\n","world\n","\n","============================================================\n","\n","📊 final_filtered_reduced_LLaVA-mix665k.json Stats\n","Total unique keys: 270\n","Duplicate keys found: 0\n","\n","🔤 Sorted Unique Keys:\n","agent\n","Allergen\n","allergen\n","antiquity\n","article\n","Bed\n","bed\n","beef\n","Beef\n","Block\n","block\n","Blood\n","blood\n","Body\n","body\n","button\n","Button\n","buttons\n","Buttons\n","carpet\n","Carpet\n","Catch\n","catch\n","Cause\n","cause\n","Cement\n","cement\n","center\n","Center\n","chalk\n","Challenge\n","challenge\n","charm\n","Charm\n","chemistry\n","cloth\n","Cloth\n","commodity\n","complaint\n","cone\n","Cone\n","Cones\n","cones\n","consolidation\n","construction\n","Construction\n","cosmos\n","Cover\n","cover\n","covering\n","Covering\n","crank\n","creation\n","Creation\n","curio\n","Curio\n","curiosity\n","Curiosity\n","decker\n","Decoration\n","decoration\n","dissent\n","draw\n","earth\n","Earth\n","Element\n","element\n","Enamel\n","enamel\n","essence\n","excavation\n","Excavation\n","exception\n","existence\n","Fabric\n","fabric\n","Facility\n","facility\n","Filler\n","filler\n","Film\n","film\n","finding\n","fixture\n","Fixture\n","float\n","Float\n","Floater\n","floater\n","fluid\n","Fluid\n","food\n","Food\n","Formation\n","formation\n","Fuel\n","fuel\n","glass\n","Glass\n","Glasses\n","glasses\n","good\n","goods\n","Goods\n","ground\n","Ground\n","Grounds\n","grounds\n","Growth\n","growth\n","hail\n","Head\n","head\n","humor\n","Humor\n","ice\n","ICE\n","Ice\n","ink\n","inks\n","insert\n","Installation\n","installation\n","instrumentation\n","Instrumentation\n","jelly\n","Jelly\n","juice\n","Juice\n","Keepsake\n","keepsake\n","Kick\n","kick\n","land\n","Land\n","layer\n","Layer\n","Lemon\n","lemon\n","Line\n","line\n","location\n","Location\n","lot\n","lots\n","Lots\n","LOVE\n","Love\n","love\n","lubricant\n","Marijuana\n","marijuana\n","marker\n","Marker\n","material\n","Material\n","matter\n","mechanism\n","Mechanism\n","Media\n","media\n","medium\n","melancholy\n","milk\n","Milk\n","mixture\n","moon\n","neighbor\n","Nest\n","nest\n","nutrient\n","Nutrient\n","object\n","Object\n","Opening\n","opening\n","ornament\n","padding\n","Padding\n","Part\n","part\n","Passion\n","passion\n","pavement\n","Pavement\n","paving\n","Portion\n","portion\n","process\n","Process\n","Prop\n","prop\n","Property\n","property\n","Props\n","props\n","protest\n","Protest\n","radiator\n","Rarity\n","rarity\n","relic\n","remains\n","Restoration\n","restoration\n","ribbon\n","Ribbon\n","rock\n","Rock\n","sample\n","Sample\n","seed\n","Seed\n","serum\n","Sheet\n","sheet\n","shiner\n","slip\n","Slip\n","Snake\n","snake\n","soil\n","Soil\n","sphere\n","square\n","stone\n","Stone\n","Strip\n","strip\n","Structure\n","structure\n","Stuff\n","stuff\n","substance\n","Surface\n","surface\n","tangle\n","textile\n","thing\n","Thing\n","thread\n","Thread\n","token\n","toy\n","Toy\n","Track\n","track\n","Trash\n","trash\n","trifle\n","trivia\n","Unit\n","unit\n","universe\n","vehicle\n","Vehicle\n","wall\n","Wall\n","WAY\n","Way\n","way\n","Ways\n","ways\n","web\n","Web\n","Weight\n","weight\n","whole\n","world\n","World\n"]}]},{"cell_type":"code","source":["from collections import defaultdict\n","import json\n","from pathlib import Path\n","\n","def load_and_normalize(filepath):\n","    with open(filepath, \"r\") as f:\n","        content = f.read()\n","\n","    blocks = [block for block in content.strip().split(\"\\n\\n\") if block.strip()]\n","    merged = defaultdict(lambda: defaultdict(int))\n","\n","    for block in blocks:\n","        try:\n","            d = json.loads(block)\n","            for key, val_dict in d.items():\n","                key_lower = key.lower()\n","                for subkey, freq in val_dict.items():\n","                    subkey_lower = subkey.lower()\n","                    merged[key_lower][subkey_lower] += freq\n","        except json.JSONDecodeError:\n","            print(\"⚠️ Skipping invalid JSON block.\")\n","\n","    return merged\n","\n","def merge_two_dictionaries(dict1, dict2):\n","    for key, subdict in dict2.items():\n","        for subkey, freq in subdict.items():\n","            dict1[key][subkey] += freq\n","    return dict1\n","\n","def sort_nested_dict(d):\n","    sorted_dict = {}\n","    for key in sorted(d.keys()):\n","        sorted_sub = dict(sorted(d[key].items(), key=lambda x: -x[1]))\n","        sorted_dict[key] = sorted_sub\n","    return sorted_dict\n","\n","# File paths\n","base_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project\")\n","pretrain_path = base_path / \"final_filtered_reduced_LLaVA-Pretrain.json\"\n","mix_path = base_path / \"final_filtered_reduced_LLaVA-mix665k.json\"\n","output_path = base_path / \"final_merged_sorted_cooccur.json\"\n","\n","# Load, normalize, and merge\n","pretrain_data = load_and_normalize(pretrain_path)\n","mix_data = load_and_normalize(mix_path)\n","merged = merge_two_dictionaries(pretrain_data, mix_data)\n","sorted_merged = sort_nested_dict(merged)\n","\n","# Save final result\n","with open(output_path, \"w\") as f:\n","    json.dump(sorted_merged, f, indent=2)\n","\n","print(f\"✅ Final merged and sorted co-occurrence data saved to:\\n{output_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BODQNmuipQZJ","executionInfo":{"status":"ok","timestamp":1744304758882,"user_tz":240,"elapsed":71,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"7f0afeb7-121f-474f-db7d-e6ccecbdd74b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Final merged and sorted co-occurrence data saved to:\n","/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\n"]}]},{"cell_type":"code","source":["# Path to the final cleaned and sorted file\n","final_json_path = Path(\"/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\")\n","\n","def verify_final_json_stats(filepath, expected_max_values=150):\n","    with open(filepath, \"r\") as f:\n","        data = json.load(f)\n","\n","    total_keys = len(data)\n","    too_many_values = {k: len(v) for k, v in data.items() if len(v) > expected_max_values}\n","\n","    print(f\"📊 Total unique main objects (keys): {total_keys}\")\n","    if too_many_values:\n","        print(f\"⚠️ Keys with more than {expected_max_values} co-occurring objects:\")\n","        for k, count in too_many_values.items():\n","            print(f\"  - {k}: {count}\")\n","    else:\n","        print(f\"✅ All keys have ≤ {expected_max_values} co-occurring objects\")\n","\n","    print(\"\\n🔍 Sample order check (first 5 keys):\")\n","    for k in list(data.keys())[:5]:\n","        print(f\"  - {k}\")\n","        print(f\"    ↳ Top 3 co-objects: {list(data[k].items())[:3]}\")\n","    print(\"\\n📌 Order of values is descending by frequency? Checking sample...\")\n","\n","    for k in list(data.keys())[:5]:\n","        freqs = list(data[k].values())\n","        if freqs != sorted(freqs, reverse=True):\n","            print(f\"⚠️ Order issue found in: {k}\")\n","        else:\n","            print(f\"✅ {k} values are correctly ordered\")\n","\n","# Run verification\n","verify_final_json_stats(final_json_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkSekuJ5rUIh","executionInfo":{"status":"ok","timestamp":1744304951139,"user_tz":240,"elapsed":45,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"c3348cf2-185c-4860-d3e8-9477413a1c65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 Total unique main objects (keys): 158\n","✅ All keys have ≤ 150 co-occurring objects\n","\n","🔍 Sample order check (first 5 keys):\n","  - agent\n","    ↳ Top 3 co-objects: [('process', 19), ('milk', 14), ('food', 9)]\n","  - allergen\n","    ↳ Top 3 co-objects: [('food', 14), ('growth', 2), ('allergen', 2)]\n","  - antiquity\n","    ↳ Top 3 co-objects: [('stone', 4), ('structure', 4), ('charm', 3)]\n","  - article\n","    ↳ Top 3 co-objects: [('cover', 23), ('media', 15), ('part', 9)]\n","  - bed\n","    ↳ Top 3 co-objects: [('wall', 365), ('surface', 275), ('part', 198)]\n","\n","📌 Order of values is descending by frequency? Checking sample...\n","✅ agent values are correctly ordered\n","✅ allergen values are correctly ordered\n","✅ antiquity values are correctly ordered\n","✅ article values are correctly ordered\n","✅ bed values are correctly ordered\n"]}]},{"cell_type":"code","source":["# Check which of the 160 objects are missing from the final JSON\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","final_json_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\"\n","\n","df = pd.read_csv(csv_path)\n","csv_objects = set(df[\"Object\"].dropna().astype(str).str.lower())\n","\n","with open(final_json_path, \"r\") as f:\n","    json_data = json.load(f)\n","json_keys = set(json_data.keys())\n","\n","missing = sorted(csv_objects - json_keys)\n","\n","print(f\"❌ Missing objects ({len(missing)}):\")\n","for obj in missing:\n","    print(f\"- {obj}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B16nX_fRreoB","executionInfo":{"status":"ok","timestamp":1744305031065,"user_tz":240,"elapsed":25,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"d3e4dd88-3ffc-4b16-f35b-8d2d12ddaa85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["❌ Missing objects (1):\n","- extra\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from collections import Counter\n","\n","# Path to the CSV file\n","csv_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/interesting_objects_v3.csv\"\n","\n","df = pd.read_csv(csv_path)\n","objects_raw = df[\"Object\"].dropna().astype(str).tolist()\n","objects_normalized = [obj.strip().lower() for obj in objects_raw]\n","\n","# Counting frequency\n","object_counter = Counter(objects_normalized)\n","\n","unique_count = len(set(objects_normalized))\n","total_count = len(objects_normalized)\n","duplicates = {obj: count for obj, count in object_counter.items() if count > 1}\n","\n","# Output\n","print(f\"🔢 Total objects (original): {total_count}\")\n","print(f\"🔡 Unique objects (normalized): {unique_count}\")\n","print(f\"♻️ Duplicate entries found: {len(duplicates)}\")\n","\n","if duplicates:\n","    print(\"\\n🔁 Duplicate examples:\")\n","    for obj, count in list(duplicates.items())[:10]:\n","        print(f\"- {obj}: {count} times\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSvg17dOsBI7","executionInfo":{"status":"ok","timestamp":1744305146191,"user_tz":240,"elapsed":14,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"92af21fb-836b-44d6-91df-132cc6b407ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["🔢 Total objects (original): 159\n","🔡 Unique objects (normalized): 159\n","♻️ Duplicate entries found: 0\n"]}]},{"cell_type":"code","source":["# Path to the final merged JSON\n","final_json_path = \"/content/drive/MyDrive/Grad/CAP6412-0001/Project/final_merged_sorted_cooccur.json\"\n","\n","with open(final_json_path, \"r\") as f:\n","    data = json.load(f)\n","\n","multi_word_keys = [k for k in data if len(k.split()) > 1]\n","multi_word_values = set()\n","\n","for co_dict in data.values():\n","    for co_obj in co_dict:\n","        if len(co_obj.split()) > 1:\n","            multi_word_values.add(co_obj)\n","\n","print(f\"Total multi-word keys: {len(multi_word_keys)}\")\n","if multi_word_keys:\n","    print(\"Sample multi-word keys:\")\n","    for k in list(multi_word_keys)[:10]:\n","        print(f\"- {k}\")\n","\n","print(f\"\\nTotal multi-word co-occurring objects (values): {len(multi_word_values)}\")\n","if multi_word_values:\n","    print(\"Sample multi-word values:\")\n","    for v in list(multi_word_values)[:10]:\n","        print(f\"- {v}\")\n"],"metadata":{"id":"6eacvCysvJRG","executionInfo":{"status":"ok","timestamp":1744305955440,"user_tz":240,"elapsed":13,"user":{"displayName":"Saurabh Agarwal","userId":"04869235735814898050"}},"outputId":"7c2d6cb9-557a-46e2-9cd9-f02dc2c137c3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total multi-word keys: 0\n","\n","Total multi-word co-occurring objects (values): 0\n"]}]}]}